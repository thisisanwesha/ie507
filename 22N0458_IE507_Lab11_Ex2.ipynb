{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simulation using Python, Lab 2, Part B"
      ],
      "metadata": {
        "id": "jCYxZA0Ksgwt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mEq66v4PziL"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploration**\n",
        "Randomly explore the search space and report the best solution found for the Rosenbrock Function"
      ],
      "metadata": {
        "id": "GrYHWMdgstZG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuQDD_oiQDC0"
      },
      "source": [
        "#Let's define the 2-D Rosenbrock function\n",
        "def Rosenbrock(x1, x2):\n",
        "  return ((1-x1)**2 + 100*(x2 -x1**2)**2)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS6qfA6jQLQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61678e82-9fe8-433a-c923-fc8da2c4ddca"
      },
      "source": [
        "N = 10000 ## number of random points\n",
        "D = 2 ##Dimension \n",
        "lb = -4 ## lower bound\n",
        "ub = 4  ## upper bound\n",
        "\n",
        "X1=[]\n",
        "X2=[]\n",
        "Y=[]\n",
        "\n",
        "#randomly generate N points. We are using Numpy's random package here.\n",
        "X1 = np.random.uniform(lb, ub, N)\n",
        "X2 = np.random.uniform(lb, ub, N)\n",
        "\n",
        "#Evaluate the function\n",
        "for i in range(N):\n",
        "    Y.append(Rosenbrock(X1[i], X2[i]))\n",
        "    \n",
        "#display Results\n",
        "print('\\n Monte Carlo Simulation Optimisation\\n')\n",
        "print( 'Best decision variable : ', X1[np.argmin(Y)], X2[np.argmin(Y)])\n",
        "print('Best objective    : ', min(Y))\n",
        "\n",
        "X_optimum = [1,1] #Known from theory\n",
        "print(\"Known Optimal decision variables:\",X_optimum)\n",
        "print(\"Known Optimal objective =\",Rosenbrock(X_optimum[0], X_optimum[1]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Monte Carlo Simulation Optimisation\n",
            "\n",
            "Best decision variable :  1.0350695384719453 1.079006522732068\n",
            "Best objective    :  0.007063125058122616\n",
            "Known Optimal decision variables: [1, 1]\n",
            "Known Optimal objective = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnTVEuMvRZEf"
      },
      "source": [
        "'Optimise' above model for different values of N.  Observe how just randomly searching the soultion space yields pretty good results!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42bS-uuXQiTP"
      },
      "source": [
        "##To Do\n",
        "\n",
        "You can find some single objective unconstrained test functions at [Wiki page](https://en.wikipedia.org/wiki/Test_functions_for_optimization)\n",
        "\n",
        "1. Through simulation, estimate the best solution of any one of the function: Beale or Goldstein-Price or Booth (need to minimize)\n",
        "\n",
        "2. 'Minimize' either Himmelblau's function OR Cross-in-Tray function. These functions have 4 alternate solutions.  Do 20 sets of 'simulation-optimisation' runs, with N ~= 200000. Compute the number of times we are close to a particular known solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq3-TrrOSxcj"
      },
      "source": [
        "#Let's define the 2-D Booth function\n",
        "def Booth(x1, x2):\n",
        "  return ((x1+2*x2-7)**2+(2*x1+x2-5)**2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 10000 ## number of random points\n",
        "D = 2 ##Dimension \n",
        "lb = -10 ## lower bound\n",
        "ub = 10  ## upper bound\n",
        "\n",
        "X1=[]\n",
        "X2=[]\n",
        "Y=[]\n",
        "\n",
        "#randomly generate N points. We are using Numpy's random package here.\n",
        "X1 = np.random.uniform(lb, ub, N)\n",
        "X2 = np.random.uniform(lb, ub, N)\n",
        "\n",
        "#Evaluate the function\n",
        "for i in range(N):\n",
        "    Y.append(Booth(X1[i], X2[i]))\n",
        "    \n",
        "#display Results\n",
        "print('Monte Carlo Simulation Optimisation of Booth function\\n')\n",
        "print('Best decision variable : [', X1[np.argmin(Y)],',',X2[np.argmin(Y)],']')\n",
        "print('Best objective :', min(Y))\n",
        "\n",
        "X_optimum = [1,3] #Known from theory\n",
        "print(\"Known Optimal decision variables:\",X_optimum)\n",
        "print(\"Known Optimal objective =\",Booth(X_optimum[0], X_optimum[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY9gc5dQz10t",
        "outputId": "42c0796c-cfe3-4062-d8f0-8a207ba93179"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monte Carlo Simulation Optimisation of Booth function\n",
            "\n",
            "Best decision variable : [ 1.1154166024604244 , 2.7778328492462574 ]\n",
            "Best objective : 0.10826195324124008\n",
            "Known Optimal decision variables: [1, 3]\n",
            "Known Optimal objective = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's define the 2-D Himmelblau's function\n",
        "def Himmelblau(x1, x2):\n",
        "  return ((x1**2+x2-11)**2+(x1+x2**2-7)**2)"
      ],
      "metadata": {
        "id": "44kCvks52OOD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 200000 ## number of random points\n",
        "D = 2 ##Dimension \n",
        "lb = -5 ## lower bound\n",
        "ub = 5  ## upper bound\n",
        "\n",
        "print(\"Monte Carlo Simulation Optimisation of Himmelblau's function\")\n",
        "a1=[3,-2.805118,-3.779310,3.584428]\n",
        "a2=[2,3.131312,-3.283186,-1.848126]\n",
        "count=[0,0,0,0]\n",
        "for i in range(20):\n",
        "  X1=[]\n",
        "  X2=[]\n",
        "  Y=[]\n",
        "  #randomly generate N points. We are using Numpy's random package here.\n",
        "  X1 = np.random.uniform(lb, ub, N)\n",
        "  X2 = np.random.uniform(lb, ub, N)\n",
        "\n",
        "  #Evaluate the function\n",
        "  for j in range(N):\n",
        "      Y.append(Himmelblau(X1[j], X2[j]))\n",
        "    \n",
        "  print('\\nNumber of iteration =',i+1)\n",
        "  print('Best decision variable : [', X1[np.argmin(Y)],',',X2[np.argmin(Y)],']')\n",
        "  print('Best objective :', min(Y))\n",
        "  for k in range(4):\n",
        "    if ((abs(X2[np.argmin(Y)]-a2[k]))<0.5):\n",
        "      count[k]=count[k]+1\n",
        "      break\n",
        "\n",
        "print()\n",
        "for k in range(4):\n",
        "  print('No of occurences of solution close to decision variable [',a1[k],',',a2[k],']=',count[k])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1Wo7dMc26_Y",
        "outputId": "dfd3c630-de0a-494b-80f2-ff3bc4b90587"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monte Carlo Simulation Optimisation of Himmelblau's function\n",
            "\n",
            "Number of iteration = 1\n",
            "Best decision variable : [ 3.5776003421600286 , -1.8437807653973293 ]\n",
            "Best objective : 0.0025084218951490034\n",
            "\n",
            "Number of iteration = 2\n",
            "Best decision variable : [ 2.9919658756978453 , 1.995423466177897 ]\n",
            "Best objective : 0.003471760221868449\n",
            "\n",
            "Number of iteration = 3\n",
            "Best decision variable : [ 2.9891674719688854 , 2.01390681569503 ]\n",
            "Best objective : 0.004621975966211304\n",
            "\n",
            "Number of iteration = 4\n",
            "Best decision variable : [ 3.578381739409064 , -1.8415382530944036 ]\n",
            "Best objective : 0.0022699666956693208\n",
            "\n",
            "Number of iteration = 5\n",
            "Best decision variable : [ 2.9943273797164913 , 2.001612066314098 ]\n",
            "Best objective : 0.001049813430391361\n",
            "\n",
            "Number of iteration = 6\n",
            "Best decision variable : [ -2.8070208449173473 , 3.130897826758215 ]\n",
            "Best objective : 0.0001255934182811407\n",
            "\n",
            "Number of iteration = 7\n",
            "Best decision variable : [ 3.0096585098256075 , 1.9951676948668968 ]\n",
            "Best objective : 0.0029245928142611383\n",
            "\n",
            "Number of iteration = 8\n",
            "Best decision variable : [ 3.0000604614886424 , 1.9986347769736765 ]\n",
            "Best objective : 3.0149430190105796e-05\n",
            "\n",
            "Number of iteration = 9\n",
            "Best decision variable : [ -3.7744486828246746 , -3.278758183918009 ]\n",
            "Best objective : 0.0016283112205437219\n",
            "\n",
            "Number of iteration = 10\n",
            "Best decision variable : [ 3.0023035497940516 , 2.0050198444207865 ]\n",
            "Best objective : 0.0008573127847225939\n",
            "\n",
            "Number of iteration = 11\n",
            "Best decision variable : [ -3.7803454664884906 , -3.2868779139250592 ]\n",
            "Best objective : 0.000556302125071952\n",
            "\n",
            "Number of iteration = 12\n",
            "Best decision variable : [ -2.807828164896179 , 3.1204773877895224 ]\n",
            "Best objective : 0.004982219642518771\n",
            "\n",
            "Number of iteration = 13\n",
            "Best decision variable : [ 3.584871092757224 , -1.838395808998441 ]\n",
            "Best objective : 0.0014218052055818885\n",
            "\n",
            "Number of iteration = 14\n",
            "Best decision variable : [ 3.5846896836507565 , -1.8415917542538418 ]\n",
            "Best objective : 0.0006395293088287528\n",
            "\n",
            "Number of iteration = 15\n",
            "Best decision variable : [ -3.7756997385203936 , -3.28136272931401 ]\n",
            "Best objective : 0.0007177794720132387\n",
            "\n",
            "Number of iteration = 16\n",
            "Best decision variable : [ 2.9933262305373196 , 2.005972754415999 ]\n",
            "Best objective : 0.001455385933648694\n",
            "\n",
            "Number of iteration = 17\n",
            "Best decision variable : [ -2.8084072521228167 , 3.1264428359901046 ]\n",
            "Best objective : 0.0013247030840921085\n",
            "\n",
            "Number of iteration = 18\n",
            "Best decision variable : [ -3.780270856590804 , -3.291205680442524 ]\n",
            "Best objective : 0.0026800835040528114\n",
            "\n",
            "Number of iteration = 19\n",
            "Best decision variable : [ -2.8074641404502234 , 3.132766666351422 ]\n",
            "Best objective : 0.00025952627731174355\n",
            "\n",
            "Number of iteration = 20\n",
            "Best decision variable : [ -3.7765204864992374 , -3.2808871591448616 ]\n",
            "Best objective : 0.000503983355109131\n",
            "\n",
            "No of occurences of solution close to decision variable [ 3 , 2 ]= 7\n",
            "No of occurences of solution close to decision variable [ -2.805118 , 3.131312 ]= 4\n",
            "No of occurences of solution close to decision variable [ -3.77931 , -3.283186 ]= 5\n",
            "No of occurences of solution close to decision variable [ 3.584428 , -1.848126 ]= 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Optional To Do"
      ],
      "metadata": {
        "id": "egDzQ619EZWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider flight IEX 306 that flies daily from Mumbai to Chennai. Flight has 100 seats.  Price of a ticket is on an average Rs. 6000.  There is 10% chance that a sold seat will remain vacant (i.e. passenger doesn’t show up). Airline refunds 50% of the price of ticket to that passenger for such last minute cancellations.  \n",
        "Daily demand for seats is Poisson distributed with mean 120.   \n",
        "Now, the airline can decide to sell $x$ tickets, where $x$ can be more or less than the capacity of plane.  \n",
        "If the airline overbooks, then it pays an average of Rs.10000 for any passenger who is ‘bumped’ (i.e. denied seat in plane). \n",
        "\n",
        "What is the value of $x$ (the number of tickets to sell) that maximizes the expected profit? (Hint: You can run the model for different values of $x$ from say 90 to 150 and choose the $x$ which gives the maximum profit)"
      ],
      "metadata": {
        "id": "XhNR0jGoEcOo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8W_g7LBEbcp"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}